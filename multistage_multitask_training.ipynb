{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training our bounding box and corner models"
      ],
      "metadata": {
        "id": "qFcSHaqxS3x1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first make any necessary imports:"
      ],
      "metadata": {
        "id": "GFV1BihRS-Y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import models, transforms\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import torchvision.ops as ops\n",
        "from transformers import SamModel, SamProcessor\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import timm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.lines as mlines\n",
        "import typing\n",
        "from itertools import chain, groupby\n",
        "from datetime import datetime\n",
        "\n",
        "!pip install --quiet optuna\n",
        "import optuna"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "mKtSFxphAwY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "BASE_PROJECT_PATH = '/content/drive/MyDrive/Erdos Institute - Solar Panels Project'\n",
        "drive.mount('/content/drive')\n",
        "sys.path.append(os.path.join(BASE_PROJECT_PATH, 'modules'))\n",
        "from solarutils import *"
      ],
      "metadata": {
        "id": "skriw0G0CBUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define our five-phase multitask training routine:"
      ],
      "metadata": {
        "id": "GheCQzrtTFEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_multitask_backbone(\n",
        "    json_file: str, image_dir: str, device: torch.device,\n",
        "    train_val_split_ratio: float = 0.8, phase0_12_split_ratio: float = 0.5,\n",
        "    phase0_epochs: int = 5, phase0_lr: float = 1e-4,\n",
        "    phase1_epochs: int = 5, phase1_lr: float = 1e-4, sigma: float = 0.5,\n",
        "    phase2_epochs: int = 10, phase2_lr: float = 1e-5,\n",
        "    phase3_epochs: int = 5, phase3_lr: float = 1e-4,\n",
        "    phase4_epochs: int = 10, phase4_lr: float = 1e-5,\n",
        "    loss_bbox_weight: float = 1.0, loss_corner_weight: float = 1.0,\n",
        "    batch_sizes: typing.List[int] = [2,4], gamma = 1.0, criterion_corner: nn.Module = nn.MSELoss(),\n",
        "    corner_strategy: str = 'basic',\n",
        "    save_path_prefix: typing.Optional[str] = None, verbose: bool = False, seed: int = 42\n",
        ") -> typing.Dict[str, typing.List[float]]:\n",
        "    \"\"\"\n",
        "    Trains bbox and corner models in five phases with validation.\n",
        "\n",
        "    Args:\n",
        "        json_file: Path to the COCO-like JSON annotation file.\n",
        "        image_dir: Path to the directory containing the images.\n",
        "        device: The device to train the models on (e.g., 'cuda' or 'cpu').\n",
        "        train_val_split_ratio: Ratio for splitting the dataset into training and validation sets.\n",
        "        phase0_12_split_ratio: Ratio for splitting the training set for phases 0, 1 and 2.\n",
        "        phase0_epochs: Number of epochs for phase 0.\n",
        "        phase0_lr: Learning rate for phase 0.\n",
        "        phase1_epochs: Number of epochs for phase 1.\n",
        "        phase1_lr: Learning rate for phase 1.\n",
        "        sigma: Learning rate adjustment factor for the bbox model in phase 1.\n",
        "        phase2_epochs: Number of epochs for phase 2.\n",
        "        phase2_lr: Learning rate for phase 2.\n",
        "        phase3_epochs: Number of epochs for phase 3.\n",
        "        phase3_lr: Learning rate for phase 3.\n",
        "        phase4_epochs: Number of epochs for phase 4.\n",
        "        phase4_lr: Learning rate for phase 4.\n",
        "        loss_bbox_weight: Weight for the bounding box loss in the combined loss.\n",
        "        loss_corner_weight: Weight for the corner loss in the combined loss.\n",
        "        batch_sizes: A list containing batch size for bbox loader and corner loader.\n",
        "        criterion_corner: The loss function for the corner model.\n",
        "        corner_strategy: The strategy for cropping the images for the corner model ('basic' or 'crop').\n",
        "        save_path_prefix: Prefix for saving the trained model weights and loss plot.\n",
        "        verbose: If True, print detailed training progress.\n",
        "        seed: Random seed for data splitting.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the training and validation loss history for each phase.\n",
        "    \"\"\"\n",
        "    # --- 1. Setup Models and Share Backbone ---\n",
        "    bbox_model = get_bbox_detection_model(num_classes=2).to(device)\n",
        "    corner_model = CornerPredictor(device, backbone=bbox_model.backbone, strategy = corner_strategy).to(device)\n",
        "    if verbose: print(\"ResNet50 with FPN backbone shared between Faster R-CNN and Corner Predictor.\")\n",
        "\n",
        "    # --- 2. Setup Datasets and Dataloaders ---\n",
        "    with open(json_file, 'r') as f:\n",
        "        all_image_ids = [img['id'] for img in json.load(f)['images']]\n",
        "\n",
        "    train_size = int(len(all_image_ids) * train_val_split_ratio)\n",
        "    train_ids, val_ids = random_split(all_image_ids, [train_size, len(all_image_ids) - train_size], generator=torch.Generator().manual_seed(seed))\n",
        "\n",
        "    p0_size = int(len(train_ids) * phase0_12_split_ratio) #size of dataset for phase 0\n",
        "    p12_size = len(train_ids) - p0_size #size of dataset for phases 1 and 2\n",
        "    p0_ids_subset, p12_ids_subset = random_split(train_ids, [p0_size, p12_size], generator=torch.Generator().manual_seed(seed))\n",
        "\n",
        "    p0_ids = [train_ids.dataset[i] for i in p0_ids_subset.indices]\n",
        "    p12_ids = [train_ids.dataset[i] for i in p12_ids_subset.indices]\n",
        "    val_ids = [all_image_ids[i] for i in val_ids.indices]\n",
        "\n",
        "    if verbose: print(\"Validation Datasets:\")\n",
        "    val_bbox_dataset = BoundingboxDataset(json_file, image_dir, transform=bbox_transform, image_ids=val_ids, verbose = verbose)\n",
        "    val_corner_dataset = SinglePanelDataset(json_file, image_dir, image_transform=corner_img_transform, mask_transform=corner_mask_transform, image_ids=val_ids, verbose = verbose)\n",
        "    val_bbox_loader = DataLoader(val_bbox_dataset, batch_size=batch_sizes[0], shuffle=False, collate_fn=collate_fn_bbox, num_workers = 2)\n",
        "    val_corner_loader = DataLoader(val_corner_dataset, batch_size=batch_sizes[1], shuffle=False, collate_fn=collate_fn_corner, num_workers = 2)\n",
        "\n",
        "\n",
        "    # Initialize loss history\n",
        "    losses: typing.Dict[str, typing.List[float]] = {\n",
        "        'bbox_train': [], 'corner_train': [],\n",
        "        'bbox_val': [], 'corner_val': [],\n",
        "        'combined_train_phase2': [],\n",
        "        'phase_boundaries': []\n",
        "    }\n",
        "\n",
        "    # For phases 0 and 1, we freeze the backbone\n",
        "    for param in bbox_model.backbone.parameters(): param.requires_grad = False\n",
        "\n",
        "    # --- 0. Phase 0: Train corner model head on first split ---\n",
        "    print(\"\\n\" + \"=\"*50 + f\"\\n--- Phase 0: Training Corner Head on {len(p0_ids)} images ---\\n\" + \"=\"*50)\n",
        "\n",
        "    if verbose: print(\"Training Datasets:\")\n",
        "    p0_corner_dataset = SinglePanelDataset(json_file, image_dir, image_transform=corner_img_transform, mask_transform=corner_mask_transform, image_ids=p0_ids, verbose = verbose)\n",
        "    train_corner_loader_p0 = DataLoader(p0_corner_dataset, batch_size=batch_sizes[1], shuffle=True, collate_fn=collate_fn_corner, num_workers = 2)\n",
        "\n",
        "    optimizer_corner_p0 = torch.optim.AdamW([p for p in corner_model.parameters() if p.requires_grad], lr=phase0_lr)\n",
        "\n",
        "    p0_train_corner, p0_val_corner = train_corner_model(corner_model, phase0_epochs, train_corner_loader_p0, optimizer_corner_p0, criterion_corner, val_corner_loader, device, verbose = verbose)\n",
        "\n",
        "    losses['corner_train'].extend(p0_train_corner)\n",
        "    losses['corner_val'].extend(p0_val_corner)\n",
        "    losses['bbox_train'].extend([np.nan] * phase0_epochs)\n",
        "    losses['bbox_val'].extend([np.nan] * phase0_epochs)\n",
        "    losses['phase_boundaries'].append(len(losses['corner_train']))\n",
        "\n",
        "    # --- 4. Phase 1: Train Heads of both models on second split ---\n",
        "    print(\"\\n\" + \"=\"*50 + f\"\\n--- Phase 1: Training Heads on {len(p12_ids)} images ---\\n\" + \"=\"*50)\n",
        "\n",
        "    if verbose: print(\"Training Datasets:\")\n",
        "    p1_bbox_dataset = BoundingboxDataset(json_file, image_dir, transform=bbox_transform, image_ids=p12_ids, verbose = verbose)\n",
        "    p1_corner_dataset = SinglePanelDataset(json_file, image_dir, image_transform=corner_img_transform, mask_transform=corner_mask_transform, image_ids=p12_ids, verbose = verbose)\n",
        "\n",
        "    train_bbox_loader_p1 = DataLoader(p1_bbox_dataset, batch_size=batch_sizes[0], shuffle=True, collate_fn=collate_fn_bbox, num_workers = 2)\n",
        "    train_corner_loader_p1 = DataLoader(p1_corner_dataset, batch_size=batch_sizes[1], shuffle=True, collate_fn=collate_fn_corner, num_workers = 2)\n",
        "\n",
        "    optimizer_bbox_p1 = torch.optim.AdamW([p for p in bbox_model.parameters() if p.requires_grad], lr=phase1_lr*sigma) #sigma is a parameter adjusting learning rate of bbox model vs corner model\n",
        "    optimizer_corner_p1 = torch.optim.AdamW([p for p in corner_model.parameters() if p.requires_grad], lr=phase1_lr)\n",
        "\n",
        "    p1_train_bbox, p1_train_corner, p1_val_bbox, p1_val_corner = train_bbox_corner_together(\n",
        "        bbox_model, corner_model, phase1_epochs, train_bbox_loader_p1, train_corner_loader_p1,\n",
        "        optimizer_bbox_p1, optimizer_corner_p1, criterion_corner, val_bbox_loader, val_corner_loader, device, gamma = gamma, verbose = verbose\n",
        "    )\n",
        "    losses['bbox_train'].extend(p1_train_bbox)\n",
        "    losses['corner_train'].extend(p1_train_corner)\n",
        "    losses['bbox_val'].extend(p1_val_bbox)\n",
        "    losses['corner_val'].extend(p1_val_corner)\n",
        "    losses['phase_boundaries'].append(len(losses['bbox_train']))\n",
        "    del p1_train_bbox, p1_train_corner, p1_val_bbox, p1_val_corner, train_bbox_loader_p1, train_corner_loader_p1, optimizer_bbox_p1, optimizer_corner_p1, p1_bbox_dataset, p1_corner_dataset\n",
        "\n",
        "    # --- 5. Phase 2: Fine-tune Shared Backbone on second split ---\n",
        "    print(\"\\n\" + \"=\"*50 + f\"\\n--- Phase 2: Fine-tuning Shared Backbone on {len(p12_ids)} images ---\\n\" + \"=\"*50)\n",
        "    for param in bbox_model.parameters(): param.requires_grad = False\n",
        "    for param in corner_model.parameters(): param.requires_grad = False\n",
        "    for param in bbox_model.backbone.parameters(): param.requires_grad = True\n",
        "\n",
        "    backbone_layers = [module for name, module in bbox_model.backbone.body.named_children() if name.startswith('layer')]+[bbox_model.backbone.fpn]\n",
        "    param_groups = [{'params': layer.parameters(), 'lr': phase2_lr / (2**(len(backbone_layers)-1-i))} for i, layer in enumerate(backbone_layers)]\n",
        "    optimizer_backbone_p2 = torch.optim.AdamW(param_groups)\n",
        "\n",
        "    if verbose: print(\"Training Datasets:\")\n",
        "    p2_bbox_dataset = BoundingboxDataset(json_file, image_dir, transform=bbox_transform, image_ids=p12_ids, return_ids = True, only_pos = True, verbose = verbose)\n",
        "    p2_corner_dataset = SinglePanelDataset(json_file, image_dir, image_transform=corner_img_transform, mask_transform=corner_mask_transform, image_ids=p12_ids, verbose = verbose)\n",
        "\n",
        "    train_bbox_loader_p2 = DataLoader(p2_bbox_dataset, batch_size=batch_sizes[0], shuffle=True, collate_fn=collate_fn_bbox, num_workers = 2)\n",
        "\n",
        "    for epoch in range(phase2_epochs):\n",
        "        train_loss_bbox = 0\n",
        "        train_loss_corner = 0\n",
        "        train_loss_combined = 0\n",
        "        bbox_model.train(); corner_model.train()\n",
        "        for images, targets, image_ids in train_bbox_loader_p2:\n",
        "            if not images: continue\n",
        "            corner_data = collate_fn_corner([p2_corner_dataset.process_annotation(ann) for image_id in image_ids for ann in p2_corner_dataset.img2ann[image_id]])\n",
        "            if corner_data[0] is None: continue #skip if collate function returns None, None, None, None\n",
        "            corner_imgs, corner_bboxes, corner_masks, corner_keypoints = corner_data\n",
        "            n_single_panels = len(corner_imgs)\n",
        "            optimizer_backbone_p2.zero_grad(set_to_none = True)\n",
        "            loss_dict_bbox = bbox_model([img.to(device) for img in images], [{k: v.to(device) for k, v in t.items()} for t in targets])\n",
        "            losses_bbox = sum(loss for loss in loss_dict_bbox.values())\n",
        "            train_loss_bbox += losses_bbox.item()\n",
        "            outputs_corner = corner_model(corner_imgs.to(device), corner_bboxes.to(device), corner_masks.to(device))\n",
        "            loss_corner = criterion_corner(outputs_corner, corner_keypoints.to(device))\n",
        "            train_loss_corner += loss_corner.item()/n_single_panels\n",
        "            combined_loss = (loss_bbox_weight * losses_bbox) + (loss_corner_weight/n_single_panels * loss_corner)\n",
        "            train_loss_combined += combined_loss.item()\n",
        "            combined_loss.backward()\n",
        "            optimizer_backbone_p2.step()\n",
        "            del images, targets, image_ids, corner_data, corner_imgs, corner_bboxes, corner_masks, corner_keypoints, loss_dict_bbox, losses_bbox, outputs_corner, loss_corner, combined_loss\n",
        "\n",
        "        avg_train_loss_bbox = train_loss_bbox / len(train_bbox_loader_p2)\n",
        "        avg_train_loss_corner = train_loss_corner / len(train_bbox_loader_p2)\n",
        "        avg_train_loss_combined = train_loss_combined / len(train_bbox_loader_p2)\n",
        "        if verbose: print(f\"Backbone Finetune - Epoch {epoch+1}, BBox Train Loss: {avg_train_loss_bbox:.4f}, Corner Train Loss: {avg_train_loss_corner:.4f}, Combined Train Loss: {avg_train_loss_combined:.4f}.\")\n",
        "        losses['bbox_train'].append(avg_train_loss_bbox)\n",
        "        losses['corner_train'].append(avg_train_loss_corner)\n",
        "        losses['combined_train_phase2'].append(avg_train_loss_combined)\n",
        "        # No validation in phase 2, so append NaN\n",
        "        losses['bbox_val'].append(float('nan'))\n",
        "        losses['corner_val'].append(float('nan'))\n",
        "    losses['phase_boundaries'].append(len(losses['bbox_train']))\n",
        "    del p2_bbox_dataset, p2_corner_dataset, train_bbox_loader_p2, optimizer_backbone_p2\n",
        "\n",
        "    # --- 6. Phase 3: Re-train Heads on Full Training Data ---\n",
        "    print(\"\\n\" + \"=\"*50 + f\"\\n--- Phase 3: Re-training Heads on {len(train_ids)} images ---\\n\" + \"=\"*50)\n",
        "    for param in bbox_model.parameters(): param.requires_grad = True\n",
        "    for param in corner_model.parameters(): param.requires_grad = True\n",
        "    for param in bbox_model.backbone.parameters(): param.requires_grad = False\n",
        "\n",
        "    optimizer_bbox_p3 = torch.optim.AdamW([p for name, p in bbox_model.named_parameters() if p.requires_grad], lr=phase3_lr)\n",
        "    optimizer_corner_p3 = torch.optim.AdamW([p for name, p in corner_model.named_parameters() if p.requires_grad], lr=phase3_lr)\n",
        "\n",
        "    if verbose: print(\"Training Datasets:\")\n",
        "    full_train_bbox_dataset = BoundingboxDataset(json_file, image_dir, transform=bbox_transform, image_ids=train_ids.indices, verbose = verbose)\n",
        "    full_train_corner_dataset = SinglePanelDataset(json_file, image_dir, image_transform=corner_img_transform, mask_transform=corner_mask_transform, image_ids=train_ids.indices, verbose = verbose)\n",
        "    full_train_bbox_loader = DataLoader(full_train_bbox_dataset, batch_size=batch_sizes[0], shuffle=True, collate_fn=collate_fn_bbox, num_workers = 2)\n",
        "    full_train_corner_loader = DataLoader(full_train_corner_dataset, batch_size=batch_sizes[1], shuffle=True, collate_fn=collate_fn_corner, num_workers = 2)\n",
        "\n",
        "    p3_train_bbox, p3_train_corner, p3_val_bbox, p3_val_corner = train_bbox_corner_together(\n",
        "        bbox_model, corner_model, phase3_epochs, full_train_bbox_loader, full_train_corner_loader,\n",
        "        optimizer_bbox_p3, optimizer_corner_p3, criterion_corner, val_bbox_loader, val_corner_loader, device, gamma = gamma, verbose = verbose\n",
        "    )\n",
        "    losses['bbox_train'].extend(p3_train_bbox)\n",
        "    losses['corner_train'].extend(p3_train_corner)\n",
        "    losses['bbox_val'].extend(p3_val_bbox)\n",
        "    losses['corner_val'].extend(p3_val_corner)\n",
        "    losses['phase_boundaries'].append(len(losses['bbox_train']))\n",
        "    del p3_train_bbox, p3_train_corner, p3_val_bbox, p3_val_corner, optimizer_bbox_p3, optimizer_corner_p3\n",
        "\n",
        "    # --- 7. Phase 4: Fine-tune Everything on Full Training Data ---\n",
        "    print(\"\\n\" + \"=\"*50 + f\"\\n--- Phase 4: Fine-tuning All Layers on {len(train_ids)} images ---\\n\" + \"=\"*50)\n",
        "    for param in bbox_model.parameters(): param.requires_grad = True\n",
        "    for param in corner_model.parameters(): param.requires_grad = True\n",
        "\n",
        "    optimizer_bbox_p4 = torch.optim.AdamW(list(bbox_model.parameters()), lr=phase4_lr)\n",
        "    optimizer_corner_p4 = torch.optim.AdamW(list(corner_model.parameters()), lr=phase4_lr)\n",
        "\n",
        "    if verbose: print(\"Training Datasets: Same as in Phase 3\")\n",
        "\n",
        "    p4_train_bbox, p4_train_corner, p4_val_bbox, p4_val_corner = train_bbox_corner_together(\n",
        "        bbox_model, corner_model, phase4_epochs, full_train_bbox_loader, full_train_corner_loader,\n",
        "        optimizer_bbox_p4, optimizer_corner_p4, criterion_corner, val_bbox_loader, val_corner_loader, device, gamma=gamma, verbose = verbose\n",
        "    )\n",
        "    losses['bbox_train'].extend(p4_train_bbox)\n",
        "    losses['corner_train'].extend(p4_train_corner)\n",
        "    losses['bbox_val'].extend(p4_val_bbox)\n",
        "    losses['corner_val'].extend(p4_val_corner)\n",
        "    losses['phase_boundaries'].append(len(losses['bbox_train']))\n",
        "    del p4_train_bbox, p4_train_corner, p4_val_bbox, p4_val_corner, optimizer_bbox_p4, optimizer_corner_p4, full_train_bbox_dataset, full_train_corner_dataset, full_train_bbox_loader, full_train_corner_loader\n",
        "\n",
        "\n",
        "    if save_path_prefix:\n",
        "        torch.save(bbox_model.state_dict(), f\"{save_path_prefix}_bbox.pth\")\n",
        "        torch.save(corner_model.state_dict(), f\"{save_path_prefix}_corner.pth\")\n",
        "        print(f\"Multi-task trained models saved with prefix: {save_path_prefix}\")\n",
        "    plot_losses(losses, save_path_prefix)\n",
        "    del bbox_model, corner_model, val_bbox_loader, val_corner_loader\n",
        "    return losses"
      ],
      "metadata": {
        "id": "-ZTBYoJpU98B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the Optuna objective, for hyperparameter tuning:"
      ],
      "metadata": {
        "id": "wWSy2vdM-ymj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial: optuna.Trial, json_file: str, image_dir: str, device: torch.device, path: str) -> float:\n",
        "    \"\"\"\n",
        "    Objective function for Optuna to minimize.\n",
        "\n",
        "    Args:\n",
        "        trial: An Optuna trial object.\n",
        "        json_file: Path to the COCO-like JSON annotation file.\n",
        "        image_dir: Path to the directory containing the images.\n",
        "        device: The device to train the models on (e.g., 'cuda' or 'cpu').\n",
        "        path: The path to save the Optuna study artifacts.\n",
        "\n",
        "    Returns:\n",
        "        float: The validation loss decrease to be maximized.\n",
        "    \"\"\"\n",
        "    # Define hyperparameters to tune using trial suggestions\n",
        "    phase0_lr = trial.suggest_float(\"phase0_lr\", 1e-4, 1e-2, log=True)\n",
        "    phase1_lr = trial.suggest_float(\"phase1_lr\", 1e-4, 1e-2, log=True)\n",
        "    phase2_lr = trial.suggest_float(\"phase2_lr\", 1e-6, 1e-4, log=True)\n",
        "    phase3_lr = trial.suggest_float(\"phase3_lr\", 1e-5, 1e-4, log=True)\n",
        "    phase4_lr = trial.suggest_float(\"phase4_lr\", 1e-6, 1e-4, log=True)\n",
        "    sigma = trial.suggest_float(\"sigma\", 0.01, 1)\n",
        "    phase0_epochs = trial.suggest_int(\"phase0_epochs\", 3, 25)\n",
        "    phase1_epochs = trial.suggest_int(\"phase1_epochs\", 3, 25)\n",
        "    phase2_epochs = trial.suggest_int(\"phase2_epochs\", 3, 25)\n",
        "    phase3_epochs = trial.suggest_int(\"phase3_epochs\", 3, 20)\n",
        "    phase4_epochs = trial.suggest_int(\"phase4_epochs\", 3, 20)\n",
        "    loss_bbox_weight = trial.suggest_float(\"loss_bbox_weight\", 0.1, 0.9)\n",
        "    loss_corner_weight = 1.0 - loss_bbox_weight # Ensure weights sum to 1\n",
        "    phase0_12_split_ratio = trial.suggest_float(\"phase0_12_split_ratio\", 0.4, 0.6)\n",
        "    batch_size_bbox = trial.suggest_int(\"batch_size_bbox\", 1, 8)\n",
        "    batch_size_corner = trial.suggest_int(\"batch_size_corner\", 1, 8)\n",
        "    batch_sizes = [batch_size_bbox, batch_size_corner]\n",
        "\n",
        "    # Fixed parameters\n",
        "    CRITERION_CORNER = nn.MSELoss()\n",
        "\n",
        "    # Paths\n",
        "    TIME = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
        "    MODEL_SAVE_PATH_PREFIX = os.path.join(path, f\"{TIME}_model\")\n",
        "\n",
        "    # Call the training function\n",
        "    losses = train_multitask_backbone(\n",
        "        json_file=json_file,\n",
        "        image_dir=image_dir,\n",
        "        device=device,\n",
        "        train_val_split_ratio=0.8,\n",
        "        phase0_12_split_ratio=phase0_12_split_ratio,\n",
        "        phase0_epochs=phase0_epochs, phase0_lr=phase0_lr,\n",
        "        phase1_epochs=phase1_epochs, sigma = sigma,\n",
        "        phase1_lr=phase1_lr,\n",
        "        phase2_epochs=phase2_epochs,\n",
        "        phase2_lr=phase2_lr,\n",
        "        phase3_epochs=phase3_epochs,\n",
        "        phase3_lr=phase3_lr,\n",
        "        phase4_epochs=phase4_epochs,\n",
        "        phase4_lr=phase4_lr,\n",
        "        loss_bbox_weight=loss_bbox_weight,\n",
        "        loss_corner_weight=loss_corner_weight,\n",
        "        batch_sizes=batch_sizes,\n",
        "        criterion_corner=CRITERION_CORNER,\n",
        "        corner_strategy='basic',\n",
        "        save_path_prefix=MODEL_SAVE_PATH_PREFIX, verbose = True\n",
        "    )\n",
        "\n",
        "    # Return the validation loss to minimize.\n",
        "    # Handle potential NaNs in phase 2 validation.\n",
        "    bbox_val_losses = [l for l in losses['bbox_val'] if not np.isnan(l)]\n",
        "    corner_val_losses = [l for l in losses['corner_val'] if not np.isnan(l)]\n",
        "\n",
        "    # Calculate the percentage of decrease between the first epoch validation loss and final validation loss\n",
        "    bbox_val_loss_decrease = (bbox_val_losses[0] - bbox_val_losses[-1]) / bbox_val_losses[0]\n",
        "    corner_val_loss_decrease = (corner_val_losses[0] - corner_val_losses[-1]) / corner_val_losses[0]\n",
        "\n",
        "    # Return the combined decrease, which we will aim to maximize\n",
        "    return bbox_val_loss_decrease + corner_val_loss_decrease"
      ],
      "metadata": {
        "id": "GC-l50OW-xi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main code block:"
      ],
      "metadata": {
        "id": "PTLSu84n-1rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================================================\n",
        "# Global definitions\n",
        "# ==========================================================================================\n",
        "# --- Configuration ---\n",
        "TIME = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
        "JSON_FILE = os.path.join(BASE_PROJECT_PATH, 'data', 'only_high_quality_training.json') #'annotations.json'\n",
        "IMAGE_DIR = os.path.join(BASE_PROJECT_PATH, 'data', 'images')\n",
        "SAM_CHECKPOINT = \"Zigeng/SlimSAM-uniform-77\" # big model: \"facebook/sam-vit-huge\", SlimSAM: \"Zigeng/SlimSAM-uniform-50\" \"Zigeng/SlimSAM-uniform-77\"\n",
        "\n",
        "OUTPUT_JSON_PATH = os.path.join(BASE_PROJECT_PATH, 'data', f'{TIME}_inf_predictions.json')\n",
        "MODEL_SAVE_PATH_PREFIX = os.path.join(BASE_PROJECT_PATH, 'models', f\"{TIME}_model\")\n",
        "OPTUNA_PATH_PREFIX = os.path.join(BASE_PROJECT_PATH, 'models', f\"hyperparameter_tuning_{TIME}\")\n",
        "\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "bbox_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "corner_img_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "corner_mask_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "# ==========================================================================================\n",
        "# Main Execution Block\n",
        "# ==========================================================================================\n",
        "\n",
        "def main():\n",
        "    pass\n",
        "\n",
        "\n",
        "    # print(\"Starting hyperparameter tuning...\")\n",
        "    # os.makedirs(OPTUNA_PATH_PREFIX, exist_ok=True)\n",
        "    # try:\n",
        "    #     study = optuna.create_study(direction=\"maximize\")\n",
        "    #     study.optimize(lambda trial: objective(trial, JSON_FILE, IMAGE_DIR, DEVICE, OPTUNA_PATH_PREFIX), n_trials=10)\n",
        "    # except RuntimeError as e:\n",
        "    #     if \"out of memory\" in str(e):\n",
        "    #         print(\">>> CUDA out of memory. Triggering memory summary...\")\n",
        "    #         print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
        "    #     raise e\n",
        "\n",
        "    # print(\"\\nHyperparameter tuning finished.\")\n",
        "    # print(\"Best trial:\")\n",
        "    # trial = study.best_trial\n",
        "\n",
        "    # print(f\"  Value: {trial.value}\")\n",
        "    # print(\"  Params: \")\n",
        "    # for key, value in trial.params.items():\n",
        "    #     print(f\"    {key}: {value}\")\n",
        "\n",
        "\n",
        "    # # # --- Training ---\n",
        "    # train_multitask_backbone(\n",
        "    #     json_file=JSON_FILE,\n",
        "    #     image_dir=IMAGE_DIR,\n",
        "    #     device=DEVICE,\n",
        "    #     train_val_split_ratio=0.8,\n",
        "    #     phase0_12_split_ratio=0.5,\n",
        "    #     phase0_epochs=10, phase0_lr=1e-2,\n",
        "    #     phase1_epochs=5, sigma = 0.5,\n",
        "    #     phase1_lr=1e-3,\n",
        "    #     phase2_epochs=5,\n",
        "    #     phase2_lr=1e-4,\n",
        "    #     phase3_epochs=12,\n",
        "    #     phase3_lr=1e-3,\n",
        "    #     phase4_epochs=5,\n",
        "    #     phase4_lr=1e-3,\n",
        "    #     loss_bbox_weight=0.01,   #useful for balancing the different scales (empirically found)\n",
        "    #     loss_corner_weight=0.99,\n",
        "    #     batch_sizes=[4,16],\n",
        "    #     gamma = 0.5,\n",
        "    #     criterion_corner=nn.MSELoss(), #nn.SmoothL1Loss(beta = 100) could perform better than MSE loss, since it exaggerates outliers less which is good in the initial training steps when the params are random\n",
        "    #     corner_strategy='basic',\n",
        "    #     save_path_prefix=MODEL_SAVE_PATH_PREFIX, verbose = True\n",
        "    # )\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "ocMpzhF_l2hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kWmrB7AoBBG2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}